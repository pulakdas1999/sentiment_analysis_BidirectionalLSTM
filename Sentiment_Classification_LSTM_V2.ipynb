{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Loading Data and preprocessing**"
      ],
      "metadata": {
        "id": "7rIhvgr6fxvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX7N4E-POOkJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('Twitter_Data.csv')\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tokenizing the whole input column**"
      ],
      "metadata": {
        "id": "RCiCmztRgB99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import itertools\n",
        "\n",
        "# Concatenate every element in the column to form a story like text data\n",
        "res = [i for i in data['clean_text']]\n",
        "X = \" \".join(res)\n",
        "\n",
        "# Tokenize the whole text data extracted\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([X])\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(\"Total no. of unique words in the whole book :\", total_words)\n",
        "\n",
        "# Printing the first 10 items in the tokenizer.word_index dictionary\n",
        "print(dict(itertools.islice(tokenizer.word_index.items(), 10)), '...')"
      ],
      "metadata": {
        "id": "_IHfljmpP7SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Converting text input sequences into sequences of the token numbers**"
      ],
      "metadata": {
        "id": "6g2KBpgEgnaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# [modi, and, you, will, not, india] ==> [1, 3, 5, 7, 6, 9]\n",
        "input_seq = []\n",
        "for messages in data['clean_text']:\n",
        "  input_seq.append(tokenizer.texts_to_sequences([messages])[0])\n",
        "\n",
        "# Padding extra zeroes to the start of sentence and converting the whole thing to a numpy array\n",
        "max_sequence_len = max([len(seq) for seq in input_seq])\n",
        "input_sequences = np.array(pad_sequences(input_seq, maxlen = max_sequence_len, padding = 'pre'))\n",
        "\n",
        "# Data to Train on (Note: We are one hot encoding the output i.e., 'y')\n",
        "X = input_sequences\n",
        "y = np.array(to_categorical(data['category'], num_classes = 3))"
      ],
      "metadata": {
        "id": "YIm3r6vLRyTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Creating the model**"
      ],
      "metadata": {
        "id": "FOQE3M9tiW-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "# Simple LSTM model\n",
        "'''model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length = max_sequence_len))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])'''\n",
        "\n",
        "# Bidirectional LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 100, input_length = max_sequence_len),\n",
        "    Bidirectional(LSTM(150, return_sequences=True)),\n",
        "    Bidirectional(LSTM(150)),\n",
        "    Dense(3, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "591k39VTSwh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07258869-faa8-4aff-b764-e97610f3f1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 52, 100)           11367900  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 52, 300)           301200    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 300)               541200    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12211203 (46.58 MB)\n",
            "Trainable params: 12211203 (46.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training the model**"
      ],
      "metadata": {
        "id": "8BNOloLtkfId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs = 40, verbose = 1, batch_size = 1024, validation_split = 0.33)"
      ],
      "metadata": {
        "id": "K5vXBuFAXDhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8522279f-f003-4e55-deb1-e97c3a9905d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "107/107 [==============================] - 34s 245ms/step - loss: 0.6437 - accuracy: 0.7144 - val_loss: 0.2643 - val_accuracy: 0.9142\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 22s 210ms/step - loss: 0.1463 - accuracy: 0.9549 - val_loss: 0.1932 - val_accuracy: 0.9387\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 22s 206ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 0.1929 - val_accuracy: 0.9421\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 21s 193ms/step - loss: 0.0578 - accuracy: 0.9835 - val_loss: 0.2223 - val_accuracy: 0.9345\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 20s 190ms/step - loss: 0.0470 - accuracy: 0.9868 - val_loss: 0.2240 - val_accuracy: 0.9430\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 19s 182ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.2204 - val_accuracy: 0.9458\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 19s 183ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.2086 - val_accuracy: 0.9479\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 18s 173ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.2230 - val_accuracy: 0.9446\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.2381 - val_accuracy: 0.9486\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 19s 174ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.2398 - val_accuracy: 0.9492\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 18s 170ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.2313 - val_accuracy: 0.9510\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 18s 168ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.2387 - val_accuracy: 0.9481\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 18s 171ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.2624 - val_accuracy: 0.9476\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 18s 168ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2606 - val_accuracy: 0.9511\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 18s 167ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.2665 - val_accuracy: 0.9489\n",
            "Epoch 16/40\n",
            "107/107 [==============================] - 18s 169ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2528 - val_accuracy: 0.9540\n",
            "Epoch 17/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.2548 - val_accuracy: 0.9515\n",
            "Epoch 18/40\n",
            "107/107 [==============================] - 18s 170ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.2536 - val_accuracy: 0.9485\n",
            "Epoch 19/40\n",
            "107/107 [==============================] - 18s 167ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.2532 - val_accuracy: 0.9566\n",
            "Epoch 20/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2434 - val_accuracy: 0.9536\n",
            "Epoch 21/40\n",
            "107/107 [==============================] - 17s 162ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2727 - val_accuracy: 0.9555\n",
            "Epoch 22/40\n",
            "107/107 [==============================] - 18s 169ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.2747 - val_accuracy: 0.9527\n",
            "Epoch 23/40\n",
            "107/107 [==============================] - 18s 169ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.2831 - val_accuracy: 0.9539\n",
            "Epoch 24/40\n",
            "107/107 [==============================] - 18s 164ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2943 - val_accuracy: 0.9571\n",
            "Epoch 25/40\n",
            "107/107 [==============================] - 18s 164ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.3250 - val_accuracy: 0.9511\n",
            "Epoch 26/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2567 - val_accuracy: 0.9532\n",
            "Epoch 27/40\n",
            "107/107 [==============================] - 18s 167ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.2633 - val_accuracy: 0.9554\n",
            "Epoch 28/40\n",
            "107/107 [==============================] - 17s 163ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2759 - val_accuracy: 0.9554\n",
            "Epoch 29/40\n",
            "107/107 [==============================] - 17s 162ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.2857 - val_accuracy: 0.9566\n",
            "Epoch 30/40\n",
            "107/107 [==============================] - 17s 164ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2653 - val_accuracy: 0.9552\n",
            "Epoch 31/40\n",
            "107/107 [==============================] - 18s 165ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2779 - val_accuracy: 0.9562\n",
            "Epoch 32/40\n",
            "107/107 [==============================] - 18s 164ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2598 - val_accuracy: 0.9567\n",
            "Epoch 33/40\n",
            "107/107 [==============================] - 17s 161ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.3307 - val_accuracy: 0.9567\n",
            "Epoch 34/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.2561 - val_accuracy: 0.9567\n",
            "Epoch 35/40\n",
            "107/107 [==============================] - 18s 166ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2595 - val_accuracy: 0.9573\n",
            "Epoch 36/40\n",
            "107/107 [==============================] - 17s 162ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2744 - val_accuracy: 0.9573\n",
            "Epoch 37/40\n",
            "107/107 [==============================] - 17s 163ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2713 - val_accuracy: 0.9581\n",
            "Epoch 38/40\n",
            "107/107 [==============================] - 17s 162ms/step - loss: 7.2299e-04 - accuracy: 0.9999 - val_loss: 0.2942 - val_accuracy: 0.9595\n",
            "Epoch 39/40\n",
            "107/107 [==============================] - 17s 161ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2629 - val_accuracy: 0.9583\n",
            "Epoch 40/40\n",
            "107/107 [==============================] - 18s 165ms/step - loss: 7.5601e-04 - accuracy: 0.9997 - val_loss: 0.2765 - val_accuracy: 0.9566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ff6fc50d540>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Saving the model**"
      ],
      "metadata": {
        "id": "8hkw2dIQD9xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "#model.save('sentiment_analysis.keras')\n",
        "new_model = load_model('sentiment_analysis.keras')"
      ],
      "metadata": {
        "id": "9Z1bLVTTXYv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Testing the model**"
      ],
      "metadata": {
        "id": "P-0tsyeHEcvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print 'y' to check how we created the output_sentiment dictionary\n",
        "output_sentiment = {0: 'neutral', 1: 'positive', 2: 'negative'}\n",
        "seed_text = [\"He is the worst\", \"He is partly good partly bad\", \"He is the best\"]\n",
        "\n",
        "for message in seed_text:\n",
        "  # Convert to token\n",
        "  token_list = tokenizer.texts_to_sequences([message])[0]\n",
        "  # Path sequences\n",
        "  token_list = pad_sequences([token_list], maxlen = max_sequence_len, padding = 'pre')\n",
        "  # Model prediction\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  print(predicted, output_sentiment[predicted[0]])"
      ],
      "metadata": {
        "id": "JBc-KDQC8Od8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6911a01-ea7a-402b-e82d-9e1e6d3ac2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "[2] negative\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[0] neutral\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[1] positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYls2ueaFiXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}